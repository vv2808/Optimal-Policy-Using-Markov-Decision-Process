{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AcCC0_c0XJU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uacgIVi66DDI"
      },
      "source": [
        "trans_data = pd.read_csv('transitions_data.csv',header=None)\n",
        "rwd_data = pd.read_csv('rewards.csv',header=None)\n",
        "trans_data = trans_data.to_numpy()\n",
        "rwd_data = rwd_data.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-nyi3jO2JE6"
      },
      "source": [
        "gamma = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk6um68B2O-V"
      },
      "source": [
        "transitions = {}\n",
        "len_data = trans_data.shape[0]\n",
        "td = trans_data\n",
        "for i in range(1,len_data):\n",
        "  if (td[i][0] in transitions):\n",
        "    if td[i][1] in transitions[td[i][0]]:\n",
        "      transitions[td[i][0]][td[i][1]].append((float(td[i][3]),td[i][2]))\n",
        "    else:\n",
        "      transitions[td[i][0]][td[i][1]] = [(float(td[i][3]),td[i][2])]\n",
        "  else:\n",
        "    transitions[td[i][0]] = {td[i][1]:[(float(td[i][3]),td[i][2])]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svMbVjID6xKT"
      },
      "source": [
        "rewards = {}\n",
        "rd = rwd_data\n",
        "len_rewards = rd.shape[0]\n",
        "for i in range(0,len_rewards):\n",
        "  rewards[rd[i][0]] = float(rd[i][1]) if rd[i][1] != 'None' else np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng46TunBFbbW",
        "outputId": "0fd281f1-5fee-4fef-c18b-4e9025e55cab"
      },
      "source": [
        "rkeys = rewards.keys()\n",
        "tkeys = transitions.keys()\n",
        "st = ''\n",
        "st2 = ''\n",
        "for i in tkeys:\n",
        "  st += i + ' '\n",
        "for j in rkeys:\n",
        "  st2 += j + ' '\n",
        "print(st)\n",
        "print(st2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3 0) (3 1) (1 0) (2 1) (1 2) (2 0) (3 2) (2 2) (0 1) (0 0) (0 2) \n",
            "(0 1) (3 0) (0 0) (1 0) (3 1) (1 1) (2 1) (1 2) (2 0) (3 2) (0 2) (2 2) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXU0_Edjq-Tp"
      },
      "source": [
        "class MarkovDecisionProcess:\n",
        "  def __init__(self, states=[], transition={}, reward={}, gamma=0.9):\n",
        "    self.states = states\n",
        "    self.transition = transition\n",
        "    self.reward = reward\n",
        "    self.gamma = gamma\n",
        "\n",
        "  def Rwd(self, state):\n",
        "    return self.reward[state]\n",
        "\n",
        "  def Trans(self, state, action):\n",
        "    return self.transition[state][action]\n",
        "\n",
        "  def action(self, state):\n",
        "    return self.transition[state].keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq4IUU7X-9fH"
      },
      "source": [
        "Transitions = transitions\n",
        "Rewards = rewards\n",
        "States = transitions.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntO6gw9qsb-i"
      },
      "source": [
        "mdp = MarkovDecisionProcess(states = States, transition = Transitions, reward = Rewards)\n",
        "epsilon = 0.2\n",
        "def val_iteration():\n",
        "  states = mdp.states\n",
        "  actions = mdp.action\n",
        "  Trans = mdp.Trans\n",
        "  Rwd = mdp.Rwd\n",
        "  V1 = {s: 0 for s in states}\n",
        "  while True:\n",
        "    V = V1.copy()\n",
        "    delta = 0\n",
        "\n",
        "    for s in states:\n",
        "      V1[s] = Rwd(s) + gamma * max([sum([p*V[s1] for (p,s1) in Trans(s,a)]) for a in actions(s)])\n",
        "      delta = max(delta, abs(V1[s]-V[s]))\n",
        "\n",
        "    if (delta < epsilon*(1-gamma)/gamma):\n",
        "      return V"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkcuuO__vql_"
      },
      "source": [
        "def expected_utility(a,s,V):\n",
        "  Trans = mdp.Trans\n",
        "  return sum([p*V[s1] for (p,s1) in Trans(s,a)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0Wv1oEwvISi"
      },
      "source": [
        "def expected_utility(a,s,V):\n",
        "  Trans = mdp.Trans\n",
        "  return sum([p*V[s1] for (p,s1) in Trans(s,a)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDBX0QPfv7jD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b422db8c-0b0e-455e-9bb3-affbb9a16613"
      },
      "source": [
        "V = val_iteration()\n",
        "print(\"State-Value\")\n",
        "for s in V:\n",
        "  print(s,' - ',V[s])\n",
        "pi = best_policy(V)\n",
        "print(\"\\n Optimal policy is \\n State - Action \")\n",
        "for s in V:\n",
        "  print(s,\" \",'-',\" \",pi[s])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State-Value\n",
            "(3 0)  -  2.6118518779566258\n",
            "(3 1)  -  -10.0\n",
            "(1 0)  -  4.0484603014043845\n",
            "(2 1)  -  5.633133936112791\n",
            "(1 2)  -  7.348949178462026\n",
            "(2 0)  -  4.611938876757595\n",
            "(3 2)  -  10.0\n",
            "(2 2)  -  8.425245372413883\n",
            "(0 1)  -  5.49111436850307\n",
            "(0 0)  -  4.691426415451711\n",
            "(0 2)  -  6.312795272532248\n",
            "\n",
            " Optimal policy is \n",
            " State - Action \n",
            "(3 0)   -   L\n",
            "(3 1)   -   EXIT\n",
            "(1 0)   -   L\n",
            "(2 1)   -   U\n",
            "(1 2)   -   R\n",
            "(2 0)   -   U\n",
            "(3 2)   -   EXIT\n",
            "(2 2)   -   R\n",
            "(0 1)   -   U\n",
            "(0 0)   -   U\n",
            "(0 2)   -   R\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcTIctKHK1Vz"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}